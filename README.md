# thesisDocs
In the recent years, wearable computing has gained attention with the new eyewear computing devices like Google Glass. Voice commands, one-handed keyboards, and smartphones have been used to provide input to the wearable devices, but these have their own limitations, and interaction with eyewear computers is still a challenge. We argue that hand gestures can provide a natural and intuitive way to provide input to eyewear computers.We develop a prototype that supports hand-based gestures as input modality for eyewear com- puters. We define a set of gestures and develop a hand-based gesture detection method optimized for our set of gestures that relies on the characteristics of the hand.Our results show that our gestures are intuitive, most of them ergonomic, easy to remember and lack ambiguity. As a complementary measurement, the results show a precision of 96.91% and a recall of 89.52% of the gesture detection method.We also discuss possible improvements for our prototype. Moreover, as a result of our obser- vations through the design process of the prototype and the result of the evaluations, we present a set of design guidelines useful for future systems supporting hand-based gestures as input modal- ity.